{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968c82d5",
   "metadata": {},
   "source": [
    "# Synchrophasor SVD-Based Real-Time Compression\n",
    "\n",
    "**Notebook purpose:**\n",
    "\n",
    "- Implement the paper *\"A Real-Time Synchrophasor Data Compression Method Using Singular Value Decomposition\"*.\n",
    "- Provide code, mathematical interpretation, inline explanations, and diagnostic plots.\n",
    "\n",
    "**Notebook structure:**\n",
    "\n",
    "1. Imports and configuration\n",
    "2. Data loading (magnitude + angle → complex phasor)\n",
    "3. PMU measurement uncertainty (ε) — how to obtain/estimate\n",
    "4. Reduced SVD (thin SVD) and per-mode SNR-based selection (paper's Algorithm 1)\n",
    "5. Sliding-window rank tracking\n",
    "6. Progressive partitioning (real-time state machine)\n",
    "7. Partition compression, reconstruction, and metrics (CR, RMSE, MADE)\n",
    "8. Visualizations and interpretation\n",
    "\n",
    "**Notes:** The notebook uses deterministic (thin) SVD (`np.linalg.svd(..., full_matrices=False)`) as in the paper. It treats ε as the PMU measurement RMS error bound and uses the criterion σ_r > ε * sqrt(h n) to select modes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports and utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "import math\n",
    "import os\n",
    "\n",
    "# plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "def mag_ang_to_complex(mag, ang_deg):\n",
    "    \"\"\"Convert magnitude (pu) and angle (degrees) to complex phasor.\"\"\"\n",
    "    ang_rad = np.deg2rad(ang_deg)\n",
    "    return mag * (np.cos(ang_rad) + 1j * np.sin(ang_rad))\n",
    "\n",
    "def ensure_2d(a):\n",
    "    arr = np.array(a)\n",
    "    if arr.ndim == 1:\n",
    "        return arr[:, None]\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ceef1b",
   "metadata": {},
   "source": [
    "## 2) Data loading\n",
    "\n",
    "Load your magnitude and angle CSV files (wide format):\n",
    "\n",
    "- Columns: `Time, V2_mag, V3_mag, ..., V2_ang, V3_ang, ...` or separate files for mag and ang.\n",
    "\n",
    "**Important:** the notebook expects **aligned timestamps** across magnitude and angle. If timestamps differ, resample or interpolate before forming complex phasors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0920b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to load magnitude and angle CSV files (edit paths to your files)\n",
    "mag_path = 'magnitude_fault.csv'   # replace with your path or uploaded file\n",
    "ang_path = 'angle_fault.csv'       # replace with your path or uploaded file\n",
    "\n",
    "if os.path.exists(mag_path) and os.path.exists(ang_path):\n",
    "    mag_df = pd.read_csv(mag_path)\n",
    "    ang_df = pd.read_csv(ang_path)\n",
    "    # assume the first column is Time\n",
    "    time = mag_df.iloc[:,0].values\n",
    "    mag = mag_df.iloc[:,1:].values\n",
    "    ang = ang_df.iloc[:,1:].values\n",
    "    # ensure shapes align\n",
    "    assert mag.shape == ang.shape, \"Magnitude and angle matrices must match shape.\"\n",
    "    print('Loaded magnitude and angle with shape', mag.shape)\n",
    "else:\n",
    "    print('Place your magnitude and angle CSV files in the notebook folder or edit the paths.\\n'\n",
    "          'This notebook will still write out the full code; you can run cells after placing your files.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80108",
   "metadata": {},
   "source": [
    "## 3) PMU measurement uncertainty (ε)\n",
    "\n",
    "Paper's approach: do not iterate; use PMU accuracy bound ε to reject modes dominated by measurement error.\n",
    "\n",
    "**Options to obtain ε:**\n",
    "\n",
    "1. **From PMU datasheet or IEEE C37.118:** use TVE or RMS error in p.u. (typical magnitudes: 1e-4 p.u. for magnitude, 1e-3 rad for angle). \n",
    "2. **Estimate from quiet window:** select a steady interval and compute RMS of residuals.\n",
    "\n",
    "**Implementation note:** Use the same ε units as the entries of Y (if Y is complex phasor in p.u., ε in p.u.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd24939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_epsilon_from_quiet(Y_quiet):\n",
    "    \"\"\"Estimate epsilon (RMS) from a quiet segment Y_quiet (h_q x n).\n",
    "    Returns scalar eps (RMS of residuals).\n",
    "    \"\"\"\n",
    "    Yq = np.array(Y_quiet, dtype=np.complex128)\n",
    "    # remove per-channel mean to isolate noise\n",
    "    residuals = Yq - np.mean(Yq, axis=0, keepdims=True)\n",
    "    eps_est = np.sqrt(np.mean(np.abs(residuals)**2))\n",
    "    return eps_est\n",
    "\n",
    "print('Estimate epsilon function ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094a0c8",
   "metadata": {},
   "source": [
    "## 4) Reduced SVD (RSVD in the paper = reduced thin SVD) and mode selection (Algorithm 1)\n",
    "\n",
    "Mathematical summary:\n",
    "\n",
    "Given windowed matrix \\(Y \\in \\mathbb{C}^{h\\times n}\\):\n",
    "\n",
    "\\(Y = U \\Sigma V^H\\), with singular values \\(\\sigma_1\\ge ... \\ge \\sigma_m\\) (m=min(h,n)).\n",
    "\n",
    "RMS contribution of mode r: \n",
    "\n",
    "\\(Y_{r,RMS} = \\sigma_r / \\sqrt{h n}\\).\n",
    "\n",
    "Measurement RMS bound: \\(E_{RMS} \\le \\epsilon\\).\n",
    "\n",
    "Mode keep criterion (paper eq. 11):\n",
    "\n",
    "\\(\\sigma_r > \\epsilon \\sqrt{h n}\\). \n",
    "\n",
    "Therefore: \\(\\rho = \\max \\{ r : \\sigma_r > \\epsilon\\sqrt{hn} \\}\\).\n",
    "\n",
    "This is non-iterative and directly uses device accuracy.\n",
    "\n",
    "Below are functions to compute SVD, compute rho, and return truncated components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59552fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rho_and_components(Y, eps):\n",
    "    \"\"\"Compute thin SVD and select rho using the paper's criterion.\n",
    "    Returns rho, Ur, Sr (vector), Vhr.\n",
    "    \"\"\"\n",
    "    Y = np.array(Y, dtype=np.complex128)\n",
    "    h, n = Y.shape\n",
    "    # thin SVD\n",
    "    U, S, Vh = np.linalg.svd(Y, full_matrices=False)\n",
    "    # threshold\n",
    "    threshold = eps * math.sqrt(h * n)\n",
    "    rho = int(np.sum(S > threshold))\n",
    "    rho = max(1, rho)\n",
    "    Ur = U[:, :rho]\n",
    "    Sr = S[:rho]\n",
    "    Vhr = Vh[:rho, :]\n",
    "    return rho, Ur, Sr, Vhr\n",
    "\n",
    "# small self-check with a random low-rank matrix\n",
    "h_test, n_test, r_test = 50, 10, 3\n",
    "A = np.random.randn(h_test, r_test) @ np.random.randn(r_test, n_test)\n",
    "# choose eps very small so all modes kept\n",
    "rho_test, U_test, S_test, Vh_test = compute_rho_and_components(A, eps=1e-12)\n",
    "print('Self-check rho (should be >= r_test):', rho_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24769dfd",
   "metadata": {},
   "source": [
    "## 5) Sliding-window rank tracking (ρ(t))\n",
    "\n",
    "Compute ρ for each sliding window to obtain a time series ρ(t). This series is used by the progressive partitioning algorithm to detect events.\n",
    "\n",
    "Paper parameters:\n",
    "- Sampling rate: 60 Hz\n",
    "- Window size h: 200 (paper choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_rho_time_series(Y_full, h, eps, step=1):\n",
    "    \"\"\"Compute rho(t) for sliding windows over Y_full (T x n) using windows of height h.\n",
    "       Returns rho_series (length ~ (T-h+1)).\n",
    "    \"\"\"\n",
    "    T, n = Y_full.shape\n",
    "    rhos = []\n",
    "    times = []\n",
    "    for start in range(0, T - h + 1, step):\n",
    "        Yw = Y_full[start:start+h, :]\n",
    "        rho, _, _, _ = compute_rho_and_components(Yw, eps)\n",
    "        rhos.append(rho)\n",
    "        times.append(start)\n",
    "    return np.array(times), np.array(rhos)\n",
    "\n",
    "print('Sliding rho function ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8695b10",
   "metadata": {},
   "source": [
    "## 6) Progressive partitioning (real-time state machine)\n",
    "\n",
    "The partitioning logic from the paper (simplified):\n",
    "\n",
    "- Maintain a buffer that accumulates windows. Monitor ρ(t).\n",
    "- If ρ increases, start a disturbance partition (φ=1).\n",
    "- While disturbance continues (ρ_avg >= α ρ_max), keep adding.\n",
    "- If ρ_avg < α ρ_max, end the disturbance partition (φ transitions) and compress.\n",
    "\n",
    "Paper settings: α=0.5, l = fs (used as stability counter), h minimum partition size is typically the window size or a multiple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e580fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_partition_and_compress(Y_full, h, eps, alpha=0.5, min_partition_len=None):\n",
    "    \"\"\"Perform progressive partitioning on Y_full and compress each partition using paper's SVD criterion.\n",
    "       Returns a list of partition metadata and reconstructed data for evaluation.\n",
    "    \"\"\"\n",
    "    if min_partition_len is None:\n",
    "        min_partition_len = h\n",
    "\n",
    "    T, n = Y_full.shape\n",
    "    partitions = []  # list of (start_idx, end_idx, rho, CR, RMSE, MADE, Y_approx)\n",
    "\n",
    "    # State variables\n",
    "    phi = 0\n",
    "    sigma = 0.0\n",
    "    ctr = 0\n",
    "    rho_max = 0\n",
    "    rho_avg = 0\n",
    "\n",
    "    buffer = np.zeros((0, n), dtype=np.complex128)\n",
    "\n",
    "    t = 0\n",
    "    prev_rho = 0\n",
    "    while t < T:\n",
    "        # append one timestamp row\n",
    "        buffer = np.vstack([buffer, Y_full[t:t+1, :]])\n",
    "        # compute rho on current buffer\n",
    "        rho_now, Ur, Sr, Vhr = compute_rho_and_components(buffer, eps)\n",
    "\n",
    "        if phi == 0:\n",
    "            # normal state\n",
    "            if rho_now > prev_rho:\n",
    "                # disturbance begins\n",
    "                phi = 1\n",
    "                sigma = rho_now\n",
    "                ctr = 1\n",
    "                rho_max = rho_now\n",
    "                rho_avg = sigma / ctr\n",
    "            else:\n",
    "                # remain in normal; if buffer long enough, compress as normal partition\n",
    "                if buffer.shape[0] >= min_partition_len:\n",
    "                    Y_approx = Ur @ np.diag(Sr) @ Vhr\n",
    "                    rho_use = rho_now\n",
    "                    h_buf = buffer.shape[0]\n",
    "                    CR_val = (h_buf * n) / (rho_use * (h_buf + n + 1))\n",
    "                    RMSE_val = np.linalg.norm(buffer - Y_approx, 'fro') / math.sqrt(h_buf * n)\n",
    "                    MADE_val = np.max(np.abs(buffer - Y_approx))\n",
    "                    partitions.append((t - h_buf + 1, t + 1, rho_use, CR_val, RMSE_val, MADE_val, Y_approx.copy()))\n",
    "                    buffer = np.zeros((0, n), dtype=np.complex128)\n",
    "        elif phi == 1:\n",
    "            # disturbance accumulating\n",
    "            sigma += rho_now\n",
    "            ctr += 1\n",
    "            rho_max = max(rho_max, rho_now)\n",
    "            rho_avg = sigma / ctr\n",
    "            if rho_avg < alpha * rho_max:\n",
    "                # end of disturbance\n",
    "                Y_approx = Ur @ np.diag(Sr) @ Vhr\n",
    "                rho_use = rho_now\n",
    "                h_buf = buffer.shape[0]\n",
    "                CR_val = (h_buf * n) / (rho_use * (h_buf + n + 1))\n",
    "                RMSE_val = np.linalg.norm(buffer - Y_approx, 'fro') / math.sqrt(h_buf * n)\n",
    "                MADE_val = np.max(np.abs(buffer - Y_approx))\n",
    "                partitions.append((t - h_buf + 1, t + 1, rho_use, CR_val, RMSE_val, MADE_val, Y_approx.copy()))\n",
    "                buffer = np.zeros((0, n), dtype=np.complex128)\n",
    "                phi = 0\n",
    "                sigma = 0\n",
    "                ctr = 0\n",
    "                rho_max = 0\n",
    "        prev_rho = rho_now\n",
    "        t += 1\n",
    "    return partitions\n",
    "\n",
    "print('Progressive partitioning and compression ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0878d6c",
   "metadata": {},
   "source": [
    "## 7) Reconstruction and evaluation\n",
    "\n",
    "Formulas recap:\n",
    "\n",
    "- \\(CR = \\dfrac{h n}{\\rho (h + n + 1)}\\)\n",
    "- \\(RMSE = \\dfrac{\\|Y - \\hat{Y}\\|_F}{\\sqrt{h n}}\\)\n",
    "- \\(MADE = \\max |Y - \\hat{Y}|\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac53c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_and_metrics(Y, Ur, Sr, Vhr):\n",
    "    Yhat = Ur @ np.diag(Sr) @ Vhr\n",
    "    h, n = Y.shape\n",
    "    rho = Sr.shape[0]\n",
    "    CR_val = (h * n) / (rho * (h + n + 1))\n",
    "    RMSE_val = np.linalg.norm(Y - Yhat, 'fro') / math.sqrt(h * n)\n",
    "    MADE_val = np.max(np.abs(Y - Yhat))\n",
    "    return Yhat, CR_val, RMSE_val, MADE_val\n",
    "\n",
    "print('Reconstruct and metrics ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668ff21",
   "metadata": {},
   "source": [
    "## 8) Visualization helpers\n",
    "\n",
    "- Plot rank series\n",
    "- Plot original vs reconstructed for a chosen channel and partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08504be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_series(times, rhos, partitions=None):\n",
    "    plt.figure()\n",
    "    plt.plot(times, rhos, '-o', label='rho')\n",
    "    if partitions:\n",
    "        for (s,e, *_ ) in partitions:\n",
    "            plt.axvspan(s, e, color='orange', alpha=0.15)\n",
    "    plt.xlabel('window start index')\n",
    "    plt.ylabel('rho')\n",
    "    plt.title('Sliding-window estimated rank (rho)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_partition_original_vs_recon(Y_full, partition, channel_index=0):\n",
    "    s, e, rho, CR_val, RMSE_val, MADE_val, Y_approx = partition\n",
    "    orig = Y_full[s:e, channel_index]\n",
    "    recon = Y_approx[:, channel_index]\n",
    "    t = np.arange(s, e)\n",
    "    plt.figure()\n",
    "    plt.plot(t, orig.real, label='orig (real part)')\n",
    "    plt.plot(t, recon.real, '--', label='recon (real part)')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('value')\n",
    "    plt.title(f'Partition {s}-{e}, rho={rho}, CR={CR_val:.2f}, RMSE={RMSE_val:.3e}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print('Plot helpers ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3593d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### How to run this notebook\n",
    "\n",
    "1. Place your magnitude and angle CSVs (or a pre-built complex phasor CSV) in the folder.\n",
    "2. Edit file paths in the Data Loading cell.\n",
    "3. Choose `h = 200` and specify `eps` from PMU spec or estimate a quiet window using the provided function.\n",
    "4. Execute the sliding rho computation, then progressive partitioning and compression.\n",
    "\n",
    "If you want, tell me now to run this notebook on the files you previously uploaded; I can execute the analysis and return output tables and figures.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
